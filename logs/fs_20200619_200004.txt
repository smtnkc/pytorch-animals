Running on cpu...

ARCHITECTURE:

AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=4, bias=True)
  )
)

features.0.weight         requires_grad = True
features.0.bias           requires_grad = True
features.3.weight         requires_grad = True
features.3.bias           requires_grad = True
features.6.weight         requires_grad = True
features.6.bias           requires_grad = True
features.8.weight         requires_grad = True
features.8.bias           requires_grad = True
features.10.weight        requires_grad = True
features.10.bias          requires_grad = True
classifier.1.weight       requires_grad = True
classifier.1.bias         requires_grad = True
classifier.4.weight       requires_grad = True
classifier.4.bias         requires_grad = True
classifier.6.weight       requires_grad = True
classifier.6.bias         requires_grad = True

TRAINING WITH PARAMS:
seed=2020
batch_size=14
epochs=20
lr=0.0001
optimizer=adam
input_size=224
debug=False
pretrained=False
device=cpu
t_start=20200619_200004


Epoch 0/19
----------
train   loss: 1.331964   acc: 0.311384   f1: 0.306907
val     loss: 1.249962   acc: 0.357143   f1: 0.230721

Epoch 1/19
----------
train   loss: 1.172765   acc: 0.398438   f1: 0.394531
val     loss: 1.159468   acc: 0.428571   f1: 0.401276

Epoch 2/19
----------
train   loss: 1.066675   acc: 0.465402   f1: 0.456968
val     loss: 0.966342   acc: 0.558036   f1: 0.555575

Epoch 3/19
----------
train   loss: 1.059591   acc: 0.496652   f1: 0.492537
val     loss: 0.881027   acc: 0.589286   f1: 0.565284

Epoch 4/19
----------
train   loss: 1.041802   acc: 0.463170   f1: 0.461276
val     loss: 1.048261   acc: 0.406250   f1: 0.306845

Epoch 5/19
----------
train   loss: 1.002946   acc: 0.495536   f1: 0.494787
val     loss: 0.840591   acc: 0.575893   f1: 0.517164

Epoch 6/19
----------
train   loss: 0.934095   acc: 0.558036   f1: 0.555631
val     loss: 0.770881   acc: 0.647321   f1: 0.635721

Epoch 7/19
----------
train   loss: 0.926925   acc: 0.581473   f1: 0.582030
val     loss: 0.746479   acc: 0.687500   f1: 0.687631

Epoch 8/19
----------
train   loss: 0.894917   acc: 0.594866   f1: 0.595142
val     loss: 0.955560   acc: 0.607143   f1: 0.596189

Epoch 9/19
----------
train   loss: 0.825604   acc: 0.660714   f1: 0.663745
val     loss: 0.726134   acc: 0.709821   f1: 0.706718

Epoch 10/19
----------
train   loss: 0.792757   acc: 0.672991   f1: 0.675343
val     loss: 0.690175   acc: 0.696429   f1: 0.697505

Epoch 11/19
----------
train   loss: 0.723680   acc: 0.716518   f1: 0.718976
val     loss: 0.553873   acc: 0.785714   f1: 0.785773

Epoch 12/19
----------
train   loss: 0.689469   acc: 0.733259   f1: 0.734300
val     loss: 0.590795   acc: 0.776786   f1: 0.770982

Epoch 13/19
----------
train   loss: 0.628694   acc: 0.738839   f1: 0.739391
val     loss: 0.608704   acc: 0.790179   f1: 0.788202

Epoch 14/19
----------
train   loss: 0.637594   acc: 0.766741   f1: 0.767513
val     loss: 0.602770   acc: 0.772321   f1: 0.772102

Epoch 15/19
----------
train   loss: 0.568567   acc: 0.772321   f1: 0.773719
val     loss: 0.529997   acc: 0.790179   f1: 0.789683

Epoch 16/19
----------
train   loss: 0.571559   acc: 0.790179   f1: 0.791919
val     loss: 0.465709   acc: 0.821429   f1: 0.818212

Epoch 17/19
----------
train   loss: 0.522027   acc: 0.812500   f1: 0.814009
val     loss: 0.519064   acc: 0.790179   f1: 0.789714

Epoch 18/19
----------
train   loss: 0.544643   acc: 0.795759   f1: 0.796664
val     loss: 0.456799   acc: 0.821429   f1: 0.821104

Epoch 19/19
----------
train   loss: 0.471808   acc: 0.816964   f1: 0.817404
val     loss: 0.474821   acc: 0.825893   f1: 0.826106

Training completed in 31m 24s
Saved loss and accuracy stats -> logs/fs_20200619_200004.csv
Saved best checkpoint ->  Epoch: 19 val loss: 0.474821   acc: 0.825893

RUNNING FOR TEST SET...
227/280 predictions are correct -> Test acc: 0.810714   f1: 0.809415
